# <b> Day 1 of learning GEN AI </b>

<div className="space-y-8">

	<div className="flex flex-wrap gap-3">
		<a
			className="inline-flex items-center gap-2 rounded-md border border-border px-3 py-2 text-sm font-semibold text-accent hover:border-accent hover:bg-accent/10"
			href="https://day-1-of-learning-gen-ai.hashnode.dev/day-1-of-learning-of-gen-ai-my-understanding#heading-temperature-in-ai-models"
			target="_blank"
			rel="noreferrer"
		>
			Read this on Hashnode
		</a>
	</div>

	<p>
		Generative AI is transforming the way we build applications, write code, and interact with machines. On Day 1 of my Generative AI learning journey, I focused on understanding the fundamental concepts behind modern AI models such as ChatGPT and other Large Language Models (LLMs).
	</p>

	<p>
		In this article, I briefly explain each concept with simple explanations and real-world examples, making it useful for beginners starting with Generative AI, Transformers, and NLP.
	</p>

	<section className="space-y-3">
		<h2> <b> What Are Transformers in Generative AI? </b> </h2>
		<p>Transformers are the core architecture behind most modern language models. Unlike older models that process text sequentially, transformers analyze entire sentences at once, allowing them to understand context more effectively.</p>
		<p><strong>Real-world example:</strong> When humans read, we understand the whole sentence together—not word by word. Transformers work the same way.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Temperature in AI Models</b></h2>
		<p>Temperature controls the randomness of an AI model’s output.</p>
		<ul className="list-disc space-y-1 pl-5">
			<li>Low temperature -> deterministic and factual responses</li>
			<li>High temperature -> creative and diverse responses</li>
		</ul>
		<p><strong>Real-world example:</strong> Low temperature is like following a strict recipe; high temperature is like experimenting while cooking.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Encoder in Transformers</b></h2>
		<p>The encoder processes and understands the input text by converting it into meaningful representations.</p>
		<p><strong>Real-world example:</strong> Carefully listening to a question before answering it.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Decoder in Transformers</b></h2>
		<p>The decoder generates the output using the information learned by the encoder.</p>
		<p><strong>Real-world example:</strong> Forming a clear response after understanding the question.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Vectors in AI</b></h2>
		<p>AI models represent words and sentences as vectors (numbers).</p>
		<p><strong>Real-world example:</strong> Images stored as pixels instead of visual descriptions.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Embeddings Explained</b></h2>
		<p>Embeddings are vector representations that capture the semantic meaning of words. Words with similar meanings have similar embeddings.</p>
		<p><strong>Real-world example:</strong> “Doctor” and “Physician” are closer in meaning than “Doctor” and “Car”.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Positional Encoding</b></h2>
		<p>Since transformers do not inherently understand word order, positional encoding provides information about each word’s position.</p>
		<p><strong>Real-world example:</strong> “Dog bites man” vs “Man bites dog” — same words, different meanings.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Semantic Meaning in NLP</b></h2>
		<p>Semantic meaning refers to understanding the intent behind words rather than their literal form.</p>
		<p><strong>Real-world example:</strong> “Can you pass the salt?” is a request, not a question about ability.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Self-Attention Mechanism</b></h2>
		<p>Self-attention helps the model focus on the most relevant words in a sentence.</p>
		<p><strong>Real-world example:</strong> In “The phone did not fit in my pocket because it was too big,” self-attention identifies that “it” refers to the phone.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Softmax Function</b></h2>
		<p>Softmax converts model outputs into probabilities, helping decide which word to generate next.</p>
		<p><strong>Real-world example:</strong> Choosing the winner based on the highest number of votes.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Multi-Head Attention</b></h2>
		<p>Multi-head attention allows the model to focus on different aspects of the text simultaneously.</p>
		<p><strong>Real-world example:</strong> Watching a movie while understanding the plot, characters, and background music at the same time.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Knowledge Cutoff in AI Models</b></h2>
		<p>A model’s knowledge cutoff is the last point in time it was trained on data.</p>
		<p><strong>Real-world example:</strong> A textbook published in 2022 cannot include events from 2024.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Tokenization in NLP</b></h2>
		<p>Tokenization breaks text into smaller units called tokens.</p>
		<p><strong>Real-world example:</strong> Splitting sentences into words or syllables for easier understanding.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Vocabulary Size</b></h2>
		<p>Vocabulary size refers to the total number of tokens a model can recognize.</p>
		<p><strong>Real-world example:</strong> A person with a larger vocabulary can express ideas more clearly.</p>
	</section>

	<section className="space-y-3">
		<h2><b>Conclusion</b></h2>
		<p>Understanding these foundational concepts has helped me see how Generative AI models actually work behind the scenes. Day 1 focused on building strong fundamentals, which is essential before diving into advanced topics like fine-tuning, prompt engineering, or AI applications.</p>
		<p>This is just the beginning of my Generative AI learning journey, and I look forward to sharing more insights as I continue learning and building.</p>
	</section>

</div>
